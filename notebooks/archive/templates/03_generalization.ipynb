{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Generalization\n",
    "\n",
    "**Research Question:** Does action-grounding generalize across different tools?\n",
    "\n",
    "This notebook:\n",
    "1. Tests cross-tool transfer (escalate → search → sendMessage)\n",
    "2. Computes 3×3 transfer matrix\n",
    "3. Analyzes probe direction similarity\n",
    "4. Visualizes activation space (t-SNE)\n",
    "\n",
    "**Key hypothesis:** If transfer accuracy > 85%, representation is general, not tool-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.logging import setup_logging\n",
    "from src.config import get_config\n",
    "from src.data.io import load_activations\n",
    "from src.analysis.probes import train_and_evaluate, load_probe, evaluate_probe\n",
    "from src.analysis.visualization import plot_transfer_matrix\n",
    "\n",
    "setup_logging(level=\"INFO\")\n",
    "config = get_config()\n",
    "\n",
    "print(\"Generalization Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Activation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full activation dataset\n",
    "dataset = load_activations(config.data.processed_dir / \"activations.parquet\")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} activation samples\")\n",
    "print(f\"\\nTool type distribution:\")\n",
    "summary = dataset.summary()\n",
    "print(summary['tools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to single position and layer for consistency\n",
    "# Use mid_response at layer 16\n",
    "dataset_filtered = dataset.filter_by_position(\"mid_response\").filter_by_layer(16)\n",
    "\n",
    "print(f\"\\nFiltered dataset: {len(dataset_filtered)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Within-Tool Baseline\n",
    "\n",
    "Train and test within each tool type to establish baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train within-tool probes\n",
    "tool_types = ['escalate', 'search', 'sendMessage']\n",
    "within_tool_accuracies = {}\n",
    "tool_probes = {}\n",
    "\n",
    "for tool in tool_types:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training on {tool.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    tool_dataset = dataset_filtered.filter_by_tool(tool)\n",
    "    \n",
    "    if len(tool_dataset) < 50:\n",
    "        print(f\"  Not enough samples for {tool}: {len(tool_dataset)}\")\n",
    "        continue\n",
    "    \n",
    "    probe, train_metrics, test_metrics = train_and_evaluate(\n",
    "        tool_dataset,\n",
    "        label_type=\"reality\",\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    within_tool_accuracies[tool] = test_metrics.accuracy\n",
    "    tool_probes[tool] = probe\n",
    "    \n",
    "    print(f\"\\n  Within-tool accuracy: {test_metrics.accuracy:.1%}\")\n",
    "\n",
    "print(\"\\nWithin-tool accuracies:\")\n",
    "for tool, acc in within_tool_accuracies.items():\n",
    "    print(f\"  {tool}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Tool Transfer Matrix\n",
    "\n",
    "**Key experiment:** Train on one tool, test on another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute full transfer matrix\n",
    "transfer_matrix = np.zeros((len(tool_types), len(tool_types)))\n",
    "\n",
    "for i, train_tool in enumerate(tool_types):\n",
    "    for j, test_tool in enumerate(tool_types):\n",
    "        print(f\"\\nTrain on {train_tool}, test on {test_tool}...\")\n",
    "        \n",
    "        # Get datasets\n",
    "        train_dataset = dataset_filtered.filter_by_tool(train_tool)\n",
    "        test_dataset = dataset_filtered.filter_by_tool(test_tool)\n",
    "        \n",
    "        if len(train_dataset) < 50 or len(test_dataset) < 50:\n",
    "            print(f\"  Insufficient data\")\n",
    "            continue\n",
    "        \n",
    "        # Train on train_tool\n",
    "        X_train, y_train = train_dataset.to_sklearn_format(\"reality\")\n",
    "        X_test, y_test = test_dataset.to_sklearn_format(\"reality\")\n",
    "        \n",
    "        from src.analysis.probes import train_probe\n",
    "        probe, _, _ = train_probe(X_train, y_train, random_state=42)\n",
    "        \n",
    "        # Test on test_tool\n",
    "        test_metrics = evaluate_probe(probe, X_test, y_test)\n",
    "        \n",
    "        transfer_matrix[i, j] = test_metrics.accuracy\n",
    "        \n",
    "        transfer_type = \"Within-tool\" if i == j else \"Cross-tool\"\n",
    "        print(f\"  {transfer_type} accuracy: {test_metrics.accuracy:.1%}\")\n",
    "\n",
    "print(\"\\nTransfer Matrix:\")\n",
    "print(pd.DataFrame(transfer_matrix, index=tool_types, columns=tool_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transfer matrix\n",
    "fig = plot_transfer_matrix(\n",
    "    transfer_matrix,\n",
    "    tool_labels=[t.capitalize() for t in tool_types],\n",
    "    title=\"Cross-Tool Transfer Accuracy\",\n",
    "    save_path=config.figures_dir / \"figure4_transfer_matrix\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average cross-tool transfer\n",
    "# Exclude diagonal (within-tool)\n",
    "mask = ~np.eye(len(tool_types), dtype=bool)\n",
    "cross_tool_accuracies = transfer_matrix[mask]\n",
    "mean_cross_tool = np.mean(cross_tool_accuracies)\n",
    "std_cross_tool = np.std(cross_tool_accuracies)\n",
    "\n",
    "mean_within_tool = np.mean(np.diag(transfer_matrix))\n",
    "\n",
    "print(f\"\\n**Transfer Statistics:**\")\n",
    "print(f\"  Mean within-tool accuracy: {mean_within_tool:.1%}\")\n",
    "print(f\"  Mean cross-tool accuracy: {mean_cross_tool:.1%} ± {std_cross_tool:.3f}\")\n",
    "print(f\"  Accuracy drop: {(mean_within_tool - mean_cross_tool):.1%}\")\n",
    "\n",
    "if mean_cross_tool > 0.85:\n",
    "    print(\"\\n  ✓ Cross-tool accuracy > 85%\")\n",
    "    print(\"  → Representation generalizes across tools!\")\n",
    "else:\n",
    "    print(f\"\\n  ✗ Cross-tool accuracy = {mean_cross_tool:.1%} < 85%\")\n",
    "    print(\"  → Generalization may be limited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. t-SNE Visualization\n",
    "\n",
    "Visualize activation space colored by tool type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for t-SNE (full dataset too large)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample 500 points (balanced across tools)\n",
    "sampled_indices = []\n",
    "for tool in tool_types:\n",
    "    tool_indices = [i for i, s in enumerate(dataset_filtered.samples) if s.tool_type == tool]\n",
    "    if len(tool_indices) > 166:\n",
    "        np.random.seed(42)\n",
    "        tool_indices = np.random.choice(tool_indices, 166, replace=False)\n",
    "    sampled_indices.extend(tool_indices)\n",
    "\n",
    "X_sample = dataset_filtered.activations[sampled_indices]\n",
    "tool_labels = [dataset_filtered.samples[i].tool_type for i in sampled_indices]\n",
    "action_labels = [dataset_filtered.samples[i].tool_used for i in sampled_indices]\n",
    "\n",
    "print(f\"Running t-SNE on {len(X_sample)} samples...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_sample)\n",
    "\n",
    "print(\"t-SNE complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE colored by tool type\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = {'escalate': 'red', 'search': 'blue', 'sendMessage': 'green'}\n",
    "\n",
    "for tool in tool_types:\n",
    "    mask = np.array([t == tool for t in tool_labels])\n",
    "    ax.scatter(\n",
    "        X_tsne[mask, 0],\n",
    "        X_tsne[mask, 1],\n",
    "        c=colors[tool],\n",
    "        label=tool.capitalize(),\n",
    "        alpha=0.6,\n",
    "        s=50,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title('Activation Space Colored by Tool Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.figures_dir / \"tsne_by_tool.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE colored by action (tool_used)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "action_colors = {True: 'green', False: 'red'}\n",
    "action_names = {True: 'Tool Used', False: 'No Tool'}\n",
    "\n",
    "for action in [True, False]:\n",
    "    mask = np.array([a == action for a in action_labels])\n",
    "    ax.scatter(\n",
    "        X_tsne[mask, 0],\n",
    "        X_tsne[mask, 1],\n",
    "        c=action_colors[action],\n",
    "        label=action_names[action],\n",
    "        alpha=0.6,\n",
    "        s=50,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title('Activation Space Colored by Tool Usage (Ground Truth)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.figures_dir / \"tsne_by_action.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Significance\n",
    "\n",
    "Is cross-tool transfer significantly above chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test on cross-tool transfer\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Test if cross-tool accuracies > 0.5 (chance)\n",
    "t_stat, p_value = ttest_1samp(cross_tool_accuracies, 0.5)\n",
    "\n",
    "print(f\"\\nOne-sample t-test (H0: accuracy = 0.5):\")\n",
    "print(f\"  t = {t_stat:.3f}\")\n",
    "print(f\"  p = {p_value:.4e}\")\n",
    "print(f\"  Significant: {p_value < 0.05}\")\n",
    "\n",
    "# Effect size\n",
    "from src.analysis.statistics import compute_effect_size\n",
    "cohen_d = (mean_cross_tool - 0.5) / std_cross_tool\n",
    "print(f\"  Cohen's d: {cohen_d:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 3 RESULTS: GENERALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nWithin-Tool Accuracy:\")\n",
    "for tool, acc in within_tool_accuracies.items():\n",
    "    print(f\"  {tool}: {acc:.1%}\")\n",
    "print(f\"  Mean: {mean_within_tool:.1%}\")\n",
    "\n",
    "print(f\"\\nCross-Tool Transfer:\")\n",
    "print(f\"  Mean accuracy: {mean_cross_tool:.1%} ± {std_cross_tool:.3f}\")\n",
    "print(f\"  Accuracy drop: {(mean_within_tool - mean_cross_tool):.1%}\")\n",
    "\n",
    "print(f\"\\nStatistical Significance:\")\n",
    "print(f\"  p-value: {p_value:.4e}\")\n",
    "print(f\"  Effect size (Cohen's d): {cohen_d:.3f}\")\n",
    "\n",
    "if mean_cross_tool > 0.85:\n",
    "    print(\"\\n✓ Cross-tool transfer > 85%\")\n",
    "    print(\"✓ Representation is general, not tool-specific\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Cross-tool transfer = {mean_cross_tool:.1%}\")\n",
    "    print(\"⚠ Generalization limited (but still above chance)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "→ **Notebook 04:** Causal intervention via steering vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
