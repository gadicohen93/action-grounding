{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Causal Intervention\n",
    "\n",
    "**Research Question:** Is the action-grounding representation causally relevant to behavior?\n",
    "\n",
    "This notebook:\n",
    "1. Extracts probe direction from trained reality probe\n",
    "2. Runs steering experiments (add/subtract direction)\n",
    "3. Computes dose-response curves\n",
    "4. Tests control (random direction)\n",
    "\n",
    "**Success criteria:** Steering changes tool call rate by >20%\n",
    "\n",
    "**Note:** This is the most challenging experiment. Null results are acceptable if reported honestly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal Intervention Experiments\n",
      "Steering config:\n",
      "  Alphas: [-2.0, -1.0, -0.5, 0.0, 0.5, 1.0, 2.0]\n",
      "  Target layer: 16\n",
      "  Samples per alpha: 50\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.logging import setup_logging\n",
    "from src.config import get_config\n",
    "from src.data.io import load_episodes\n",
    "from src.analysis.probes import load_probe, get_probe_direction\n",
    "from src.intervention.steering import run_steering_experiment, compute_dose_response, plot_dose_response\n",
    "\n",
    "setup_logging(level=\"INFO\")\n",
    "config = get_config()\n",
    "\n",
    "print(\"Causal Intervention Experiments\")\n",
    "print(f\"Steering config:\")\n",
    "print(f\"  Alphas: {config.steering.alphas}\")\n",
    "print(f\"  Target layer: {config.steering.target_layer}\")\n",
    "print(f\"  Samples per alpha: {config.steering.n_samples_per_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Probe and Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 10:54:58,870 - src.analysis.probes - INFO - Loaded probe from: data/processed/reality_probe.pkl\n",
      "Loaded reality probe\n",
      "  Direction shape: (4096,)\n",
      "  Direction norm: 13.468\n"
     ]
    }
   ],
   "source": [
    "# Load trained reality probe\n",
    "reality_probe = load_probe(config.data.processed_dir / \"reality_probe.pkl\")\n",
    "\n",
    "# Get probe direction\n",
    "probe_direction = get_probe_direction(reality_probe)\n",
    "\n",
    "print(f\"Loaded reality probe\")\n",
    "print(f\"  Direction shape: {probe_direction.shape}\")\n",
    "print(f\"  Direction norm: {np.linalg.norm(probe_direction):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 10:56:18,676 - src.data.io - INFO - Loading episodes from: ../data/processed/episodes_v2.parquet\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Episode\ncategory\n  Input should be 'true_action', 'fake_action', 'honest_no_action' or 'silent_action' [type=enum, input_value='wrong_tool', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\ntool_used_any\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\nwrong_tool_name\n  Extra inputs are not permitted [type=extra_forbidden, input_value='sendMessage', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load episodes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m episodes_collection = \u001b[43mload_episodes\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/processed/episodes_v2.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Filter to interesting cases for steering\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Test 1: Can we steer fake_action (claims but no tool) to actually call tool?\u001b[39;00m\n\u001b[32m      6\u001b[39m fake_episodes = episodes_collection.get_fake_episodes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/action-grounding/notebooks/../src/data/io.py:55\u001b[39m, in \u001b[36mload_episodes\u001b[39m\u001b[34m(path, validate)\u001b[39m\n\u001b[32m     52\u001b[39m suffix = path.suffix.lower()\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suffix == \u001b[33m\"\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     episodes = \u001b[43m_load_episodes_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m suffix == \u001b[33m\"\u001b[39m\u001b[33m.jsonl\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     57\u001b[39m     episodes = _load_episodes_jsonl(path, validate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/action-grounding/notebooks/../src/data/io.py:119\u001b[39m, in \u001b[36m_load_episodes_parquet\u001b[39m\u001b[34m(path, validate)\u001b[39m\n\u001b[32m    116\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mtool_call_args\u001b[39m\u001b[33m\"\u001b[39m] = json.loads(data[\u001b[33m\"\u001b[39m\u001b[33mtool_call_args\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     episode = \u001b[43mEpisode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    121\u001b[39m     episode = Episode.model_construct(**data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/action-grounding/venv/lib/python3.11/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for Episode\ncategory\n  Input should be 'true_action', 'fake_action', 'honest_no_action' or 'silent_action' [type=enum, input_value='wrong_tool', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\ntool_used_any\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\nwrong_tool_name\n  Extra inputs are not permitted [type=extra_forbidden, input_value='sendMessage', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "# Load episodes\n",
    "episodes_collection = load_episodes(\"../data/processed/episodes_v2.parquet\")\n",
    "\n",
    "# Filter to interesting cases for steering\n",
    "# Test 1: Can we steer fake_action (claims but no tool) to actually call tool?\n",
    "fake_episodes = episodes_collection.get_fake_episodes()\n",
    "\n",
    "# Test 2: Can we steer true_action to not call tool?\n",
    "true_episodes = episodes_collection.filter_by_category('true_action').episodes\n",
    "\n",
    "print(f\"\\nEpisodes for steering:\")\n",
    "print(f\"  Fake actions: {len(fake_episodes)}\")\n",
    "print(f\"  True actions: {len(true_episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample episodes for steering (to keep compute manageable)\n",
    "n_samples = config.steering.n_samples_per_alpha\n",
    "\n",
    "np.random.seed(42)\n",
    "if len(fake_episodes) > n_samples:\n",
    "    fake_sample = np.random.choice(fake_episodes, n_samples, replace=False).tolist()\n",
    "else:\n",
    "    fake_sample = fake_episodes\n",
    "\n",
    "if len(true_episodes) > n_samples:\n",
    "    true_sample = np.random.choice(true_episodes, n_samples, replace=False).tolist()\n",
    "else:\n",
    "    true_sample = true_episodes\n",
    "\n",
    "print(f\"\\nSampled for steering:\")\n",
    "print(f\"  Fake: {len(fake_sample)}\")\n",
    "print(f\"  True: {len(true_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Steering Experiment: Fake → True\n",
    "\n",
    "**Test:** Add probe direction to fake_action episodes. Does this cause tool calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run steering on fake episodes with positive alphas\n",
    "# WARNING: This takes ~1-2 hours depending on GPU\n",
    "# Checkpointing enabled: progress is saved incrementally and will resume if interrupted\n",
    "\n",
    "checkpoint_path = config.data.processed_dir / \"fake_steering_checkpoint.json\"\n",
    "\n",
    "fake_steering_results = run_steering_experiment(\n",
    "    probe_direction=probe_direction,\n",
    "    episodes=fake_sample,\n",
    "    alphas=config.steering.alphas,\n",
    "    model_id=config.model.id,\n",
    "    target_layer=config.steering.target_layer,\n",
    "    verbose=True,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")\n",
    "\n",
    "print(f\"\\nCompleted {len(fake_steering_results)} steering experiments on fake episodes\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dose-response for fake episodes\n",
    "fake_dose_response = compute_dose_response(fake_steering_results)\n",
    "\n",
    "print(\"\\nDose-response (Fake Episodes):\")\n",
    "for alpha, rate in zip(fake_dose_response['alphas'], fake_dose_response['tool_rates']):\n",
    "    print(f\"  α = {alpha:+.1f}: tool_rate = {rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Steering Experiment: True → Fake\n",
    "\n",
    "**Test:** Subtract probe direction from true_action episodes. Does this suppress tool calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run steering on true episodes with negative alphas\n",
    "# WARNING: This takes ~1-2 hours depending on GPU\n",
    "# Checkpointing enabled: progress is saved incrementally and will resume if interrupted\n",
    "\n",
    "checkpoint_path = config.data.processed_dir / \"true_steering_checkpoint.json\"\n",
    "\n",
    "true_steering_results = run_steering_experiment(\n",
    "    probe_direction=probe_direction,\n",
    "    episodes=true_sample,\n",
    "    alphas=config.steering.alphas,\n",
    "    model_id=config.model.id,\n",
    "    target_layer=config.steering.target_layer,\n",
    "    verbose=True,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")\n",
    "\n",
    "print(f\"\\nCompleted {len(true_steering_results)} steering experiments on true episodes\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dose-response for true episodes\n",
    "true_dose_response = compute_dose_response(true_steering_results)\n",
    "\n",
    "print(\"\\nDose-response (True Episodes):\")\n",
    "for alpha, rate in zip(true_dose_response['alphas'], true_dose_response['tool_rates']):\n",
    "    print(f\"  α = {alpha:+.1f}: tool_rate = {rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Control: Random Direction\n",
    "\n",
    "**Test:** Steering with a random direction should have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random direction (same dimensionality)\n",
    "np.random.seed(42)\n",
    "random_direction = np.random.randn(len(probe_direction))\n",
    "random_direction = random_direction / np.linalg.norm(random_direction)\n",
    "\n",
    "print(f\"Random direction shape: {random_direction.shape}\")\n",
    "print(f\"Random direction norm: {np.linalg.norm(random_direction):.3f}\")\n",
    "\n",
    "# Cosine similarity with probe direction (should be ~0)\n",
    "cosine_sim = np.dot(probe_direction / np.linalg.norm(probe_direction), random_direction)\n",
    "print(f\"Cosine similarity with probe: {cosine_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample smaller subset for control (to save compute)\n",
    "control_sample = fake_sample[:20]\n",
    "\n",
    "# Run steering with random direction\n",
    "# Checkpointing enabled: progress is saved incrementally and will resume if interrupted\n",
    "checkpoint_path = config.data.processed_dir / \"control_steering_checkpoint.json\"\n",
    "\n",
    "control_results = run_steering_experiment(\n",
    "    probe_direction=random_direction,\n",
    "    episodes=control_sample,\n",
    "    alphas=config.steering.alphas,\n",
    "    model_id=config.model.id,\n",
    "    target_layer=config.steering.target_layer,\n",
    "    verbose=True,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")\n",
    "\n",
    "control_dose_response = compute_dose_response(control_results)\n",
    "\n",
    "print(\"\\nControl dose-response (Random Direction):\")\n",
    "for alpha, rate in zip(control_dose_response['alphas'], control_dose_response['tool_rates']):\n",
    "    print(f\"  α = {alpha:+.1f}: tool_rate = {rate:.1%}\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "**Figure 6:** Dose-response curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dose-response plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Fake episodes (adding direction should increase tool calls)\n",
    "ax.plot(\n",
    "    fake_dose_response['alphas'],\n",
    "    fake_dose_response['tool_rates'],\n",
    "    'o-',\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label='Fake Episodes (baseline: no tool)',\n",
    "    color='red',\n",
    ")\n",
    "\n",
    "# True episodes (subtracting direction should decrease tool calls)\n",
    "ax.plot(\n",
    "    true_dose_response['alphas'],\n",
    "    true_dose_response['tool_rates'],\n",
    "    's-',\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label='True Episodes (baseline: tool used)',\n",
    "    color='green',\n",
    ")\n",
    "\n",
    "# Control (should be flat)\n",
    "ax.plot(\n",
    "    control_dose_response['alphas'],\n",
    "    control_dose_response['tool_rates'],\n",
    "    '^--',\n",
    "    linewidth=1,\n",
    "    markersize=6,\n",
    "    label='Control (random direction)',\n",
    "    color='gray',\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "ax.axhline(y=0.5, color='k', linestyle=':', linewidth=1, alpha=0.5)\n",
    "ax.axvline(x=0, color='k', linestyle=':', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Steering Strength (α)', fontsize=14)\n",
    "ax.set_ylabel('Tool Call Rate', fontsize=14)\n",
    "ax.set_title('Steering Vector Dose-Response Curves', fontsize=16)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.figures_dir / \"figure6_steering_dose_response.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(config.figures_dir / \"figure6_steering_dose_response.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Effect Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect on fake episodes\n",
    "baseline_fake_rate = fake_dose_response['tool_rates'][fake_dose_response['alphas'].index(0.0)]\n",
    "max_alpha_idx = fake_dose_response['alphas'].index(max(config.steering.alphas))\n",
    "max_fake_rate = fake_dose_response['tool_rates'][max_alpha_idx]\n",
    "\n",
    "fake_effect_size = max_fake_rate - baseline_fake_rate\n",
    "\n",
    "print(f\"\\n**Effect on Fake Episodes:**\")\n",
    "print(f\"  Baseline (α=0): {baseline_fake_rate:.1%}\")\n",
    "print(f\"  Max steering (α={max(config.steering.alphas)}): {max_fake_rate:.1%}\")\n",
    "print(f\"  Effect size: {fake_effect_size:+.1%}\")\n",
    "\n",
    "if abs(fake_effect_size) > 0.20:\n",
    "    print(f\"  ✓ Effect > 20% - Causal evidence!\")\n",
    "else:\n",
    "    print(f\"  ✗ Effect < 20% - Weak or no causal effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect on true episodes\n",
    "baseline_true_rate = true_dose_response['tool_rates'][true_dose_response['alphas'].index(0.0)]\n",
    "min_alpha_idx = true_dose_response['alphas'].index(min(config.steering.alphas))\n",
    "min_true_rate = true_dose_response['tool_rates'][min_alpha_idx]\n",
    "\n",
    "true_effect_size = baseline_true_rate - min_true_rate\n",
    "\n",
    "print(f\"\\n**Effect on True Episodes:**\")\n",
    "print(f\"  Baseline (α=0): {baseline_true_rate:.1%}\")\n",
    "print(f\"  Min steering (α={min(config.steering.alphas)}): {min_true_rate:.1%}\")\n",
    "print(f\"  Effect size: {true_effect_size:+.1%}\")\n",
    "\n",
    "if abs(true_effect_size) > 0.20:\n",
    "    print(f\"  ✓ Effect > 20% - Causal evidence!\")\n",
    "else:\n",
    "    print(f\"  ✗ Effect < 20% - Weak or no causal effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control check (should be flat)\n",
    "control_rates = control_dose_response['tool_rates']\n",
    "control_variance = np.var(control_rates)\n",
    "\n",
    "print(f\"\\n**Control (Random Direction):**\")\n",
    "print(f\"  Mean rate: {np.mean(control_rates):.1%}\")\n",
    "print(f\"  Variance: {control_variance:.4f}\")\n",
    "\n",
    "if control_variance < 0.01:\n",
    "    print(f\"  ✓ Control is flat (low variance)\")\n",
    "else:\n",
    "    print(f\"  ⚠ Control shows variation (unexpected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Steered Generations\n",
    "\n",
    "Show concrete examples of steering effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find examples where steering caused tool call\n",
    "successful_steers = [\n",
    "    r for r in fake_steering_results\n",
    "    if r.alpha > 0 and not r.original_tool_used and r.steered_tool_used\n",
    "]\n",
    "\n",
    "print(f\"\\nFound {len(successful_steers)} successful steering cases (fake → tool call)\")\n",
    "\n",
    "if successful_steers:\n",
    "    # Show first example\n",
    "    example = successful_steers[0]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXAMPLE: Steering Induced Tool Call\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Episode ID: {example.episode_id}\")\n",
    "    print(f\"Steering strength: α = {example.alpha}\")\n",
    "    print(f\"\\nOriginal reply (no tool):\")\n",
    "    print(example.original_reply[:300] + \"...\")\n",
    "    print(f\"\\nSteered reply (tool call added):\")\n",
    "    print(example.steered_reply[:300] + \"...\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 4 RESULTS: CAUSAL INTERVENTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nSteering on Fake Episodes:\")\n",
    "print(f\"  Baseline tool rate (α=0): {baseline_fake_rate:.1%}\")\n",
    "print(f\"  Max steering tool rate: {max_fake_rate:.1%}\")\n",
    "print(f\"  Effect: {fake_effect_size:+.1%}\")\n",
    "\n",
    "print(f\"\\nSteering on True Episodes:\")\n",
    "print(f\"  Baseline tool rate (α=0): {baseline_true_rate:.1%}\")\n",
    "print(f\"  Min steering tool rate: {min_true_rate:.1%}\")\n",
    "print(f\"  Effect: {true_effect_size:+.1%}\")\n",
    "\n",
    "print(f\"\\nControl (Random Direction):\")\n",
    "print(f\"  Variance: {control_variance:.4f}\")\n",
    "\n",
    "# Overall assessment\n",
    "if abs(fake_effect_size) > 0.20 or abs(true_effect_size) > 0.20:\n",
    "    print(\"\\n✓ CAUSAL EVIDENCE: Steering changes behavior by >20%\")\n",
    "    print(\"✓ The probe direction is causally relevant!\")\n",
    "else:\n",
    "    print(\"\\n⚠ WEAK CAUSAL EVIDENCE: Effect < 20%\")\n",
    "    print(\"  Representation may be correlational, not causal\")\n",
    "    print(\"  OR: Steering method needs refinement\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honest Assessment\n",
    "\n",
    "**Note for write-up:**\n",
    "\n",
    "If steering works:\n",
    "- Strong causal evidence that probe detects action-grounding\n",
    "- Can induce/suppress tool calls by adding/subtracting direction\n",
    "\n",
    "If steering doesn't work:\n",
    "- Still have strong correlational evidence from Notebooks 01-03\n",
    "- Steering failure could mean:\n",
    "  - Representation is predictive but not causally determining\n",
    "  - Steering method needs refinement (wrong layer, wrong strength)\n",
    "  - Model has redundant circuits that compensate\n",
    "- This is STILL a valuable finding - shows limits of linear probing\n",
    "\n",
    "**Either outcome is publishable if reported honestly.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (interpret venv)",
   "language": "python",
   "name": "interpret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
